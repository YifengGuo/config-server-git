# for querying datasource configuration
elastic {
  cluster-name = "es-jw-darpa"
  cluster-nodes = "172.16.150.172"
  tcp-port = "29300"
  # This instructs the sink to emit after every element, otherwise they would be buffered
  buffer-size = "1"
  query-scroll-size = 1000
  # scroll context keep time
  keep-context-alive-sec = 120
}

kafka {
  bootstrap.servers = "172.16.150.189:9092"
  zookeeper = "172.16.150.189:2181"
}

sharded-jedis {
  hosts = "172.16.150.189:6379"
  pool_config {
    max_total = 64
    max_idle = 64
    min_idle = 16
    test_while_idle = true
    # 15 seconds
    max_wait_mills = 15000
  }
}

app {
  server.port = 9989
  scratch-interval-sec = 10
  slice-size = 1800000

  time_field = "@timestamp"
  user_field = "user"
  group_fields = ["role", "department"]

  config-refresh-interval-sec = 5
  max-data-source-count = 100

  date_range {
    from = 1522512000000
    # default 3000/00/00 00:00:00
    to = 32503651200000
  }
}